{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  0,  1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A diagonal matrix\n",
    "D = torch.diag(torch.tensor([-1, 2, 1]))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -2, -3],\n",
       "        [ 8, 10, 12],\n",
       "        [ 7,  8,  9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  4,  3],\n",
       "        [-4, 10,  6],\n",
       "        [-7, 16,  9]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_vector = torch.tensor([-1, 2, 1])\n",
    "scaled_A = A * scaling_vector\n",
    "scaled_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1, d2 = 3, 4\n",
    "example_tens = torch.arange(d1 * d2).reshape(d1, d2)\n",
    "example_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vect = torch.tensor([1, 1, 1, 1])\n",
    "base_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(example_tens.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3]],\n",
       "\n",
       "        [[ 4,  5,  6,  7]],\n",
       "\n",
       "        [[ 8,  9, 10, 11]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens_dim = example_tens.unsqueeze(1)\n",
    "example_tens_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "print(example_tens_dim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens = torch.arange(d1 * d2).reshape(d1, d2)\n",
    "example_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0],\n",
       "         [ 1,  1,  1,  1],\n",
       "         [ 2,  2,  2,  2],\n",
       "         [ 3,  3,  3,  3]],\n",
       "\n",
       "        [[ 4,  4,  4,  4],\n",
       "         [ 5,  5,  5,  5],\n",
       "         [ 6,  6,  6,  6],\n",
       "         [ 7,  7,  7,  7]],\n",
       "\n",
       "        [[ 8,  8,  8,  8],\n",
       "         [ 9,  9,  9,  9],\n",
       "         [10, 10, 10, 10],\n",
       "         [11, 11, 11, 11]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens_scaled = example_tens.unsqueeze(-1) * base_vect.unsqueeze(0).unsqueeze(0)\n",
    "example_tens_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens_scaled[0]  # The first sequence, embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens_scaled[0, 0]  # The first sequence, first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [4, 4, 4, 4],\n",
       "        [8, 8, 8, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tens_scaled[:, 0, :]  # The first batch (as an embedded sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.]],\n",
       "\n",
       "        [[ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.]],\n",
       "\n",
       "        [[ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.],\n",
       "         [11., 11., 11., 11.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.]],\n",
       "\n",
       "        [[ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.]],\n",
       "\n",
       "        [[ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.],\n",
       "         [11., 11., 11., 11.]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from embedding import PotentialSpinEncoding\n",
    "\n",
    "enc = PotentialSpinEncoding(4, 3, test_init_base=base_vect.to(dtype=torch.float32))\n",
    "example_embedded = enc(example_tens, example_tens)\n",
    "example_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
